# 그럼 안에 들어있는 값을 한번 볼게요.

from sentence_transformers import SentenceTransformer

model = SentenceTransformer("upskyy/bge-m3-korean")

print(1)

embeddings = model.encode("이 문장은 임베딩할 문장입니다.")
print(embeddings)


"""
[ 0.0598509  -0.0231357  -0.04017537 -0.07049484  0.11233961 -0.04271231
  0.04746308  0.05256315  0.01244436  0.03720802  0.02141919  0.01420724
  0.07172457 -0.02487511 -0.00987076  0.0259443   0.04798095 -0.04434299
 -0.02156419 -0.02718226  0.03152306  0.02559332 -0.05931169  0.05594838
  0.03291693  0.03592114 -0.03525929  0.03688064  0.05806384 -0.03951352
 -0.04632602 -0.02673619  0.02828353 -0.05132514  0.04165838  0.01645083
 -0.01413232 -0.04521994  0.05731793 -0.0719898  -0.00130826 -0.01590485
  0.06100196  0.05971116  0.0527143   0.04169882 -0.00736084  0.07812669
 -0.07387598 -0.00830975 -0.05196279  0.07753628  0.03399996  0.05667492
"""

# 뭐 요런 식으로 뜨는데.... 방금 말했던 것처럼 해석하면 돼요.

# 첫 번째는 남자, 두 번째는 여자, 세 번째는 용맹함, 네 번째는 권력 등.... 이런 단어들에 대해서 점수를 매긴 거죠.

# 그렇다면 어떻게 비교를 할 것인가? 원래같았으면 점과 점 점사이의 거리 공식을 활용해서 비교를 했어야 할텐데,
# 다행이도 이것까지 제공이 되어있어요.

# 우선 비교를 할 문장이 필요하기 때문에 임베딩2를 만들어볼게요.
embeddings2 = model.encode("이 문장은 비교를 할 문장입니다.")
print(embeddings2)

# 그리고 model.similarity를 통해서 비교를 해볼게요.
similarities = model.similarity(embeddings, embeddings2)
print(similarities)

# 음.. .0.48점이 나왔죠?
# 즉, 0.48만큼 비슷하다는 걸 알 수가 있어요.

# 그럼 완전히 다른 문장이라면 어떻게 될까요?
embeddings3 = model.encode("python!")
similarities = model.similarity(embeddings, embeddings3)
print(similarities)

# 굉장히 낮아졌죠? 즉, 비슷할수록 높은 점수가 나오고, 비슷하지 않을수록 낮은 점수가 나오는 걸 알 수 있어요.
